<?xml version="1.0" encoding="UTF-8"?>
<guide>
<section title="Query language">
<step>
<doc>The user interface is about to run in demo mode. It is going to walk
through a number of QRAWL queries, illustrating the capabilities of the language.
For that we need a dataset. We'll use ([httplogs][1]) (please click the name
to load it, and wait until there is a success notification at the bottom of the screen).

* httplogs ([load][1])
[1]:javascript:load_dataset("httplogs")
</doc>
</step>

<step>
<doc>The query below should execute successfully and return a number of rows.
Have a quick look to the httplogs table content displayed on the right side
of the screen. Rows are plain records with information about requests
issued to an HTTP server.

If this doesn't work, then go back to the previous step and ensure the dataset is loaded.
</doc>
<query>select * from httplogs where size > 20000</query>
</step>

    <step>
        <query>select * from httplogs where size > 20000 and method = "POST"</query>
        <doc>
            QRAWL is intended to be compatible with SQL and can perform typical filtering operations.
        </doc>
    </step>

    <step>
        <query>select distinct method, count(*) from httplogs group by method</query>
        <doc>Typical SQL aggregation are supported. Here we report the number of
            requests in each possible method.
        </doc>
    </step>

    <step>
        <query>select distinct method, count(*) from httplogs group by method</query>
        <doc>
In QRAWL, the star sign is in fact an alias to *the subset of httplogs having a certain method*, and the
count operator runs on that collection and returns the number of elements it contains. This means
the star sign can be handled as a collection itself. Click next to see.
        </doc>
    </step>

    <step>
        <query>select distinct method, * from httplogs group by method</query>
        <doc>Here we removed the aggregation function (count), so that the query returns
rows which now contain a *nested list* of log lines (the ones with the corresponding method)
in plae of the initial count.
Let's do some more processing on this inner collection.
        </doc>
    </step>

    <step>
        <query>select distinct method, (select returned from *) from httplogs group by method</query>
        <doc>We extract the return codes form that inner collection.
        </doc>
    </step>

    <step>
        <query>select distinct method, (select returned from *) from httplogs group by method</query>
<doc>We think using the star sign in a *from* is not very readable (but it does work).
We prefer to use the *partition* keyword instead. For now one consider the
*partition* keyword as an alias to the star sign for the grouped queries (there is a difference
and we'll see later on other queries). Let's use partition (click next).
</doc>
    </step>

    <step>
        <query>select distinct method, (select returned from partition) from httplogs group by method</query>
        <doc>It is more readable. Let's do more queries.
        </doc>
    </step>

    <step>
        <query>
            select distinct method, (select distinct returned, count(partition)
                                     from partition group by returned)
            from httplogs
            group by method
        </query>
        <doc>We do an inner group by on the grouped data. That query returns one row
per method, and each row contains a field being a list of returned codes
associated to the number of requests which returned that code
(and having already been filtered on the related upper
method).

But we can also extract the logs themselves instead of counting them. We only need
to use *partition* (click next).
        </doc>
    </step>


    <step>
        <doc>Now we find the original log rows in the inner list. As expected, the logs
            found in the inner nested list are all of the corresponding method and returned.
        </doc>
        <query>
            select distinct method, (select distinct returned, partition
                                     from partition group by returned)
            from httplogs
            group by method
        </query>
    </step>

    <step>
        <doc>This is it for nested queries. Now let's review the scripting capabilities
            of QRAWL.
        </doc>
        <query>
        </query>
    </step>

    </section>
    <section title="Scripting">

    <step>
        <query>
            {
                x := 32768;
                large := select * from httplogs where size >= x;
                large // returned value
            }
        </query>
        <doc>QRAWL supports variable assignments to simplify the edition of queries.

Below we assign an integer value to *x*, then we store results of a *select* in *large*,
finally the program returns the value of *large*.
        </doc>
    </step>

    <step>
        <query>
            {
                x := 32768;
                large := select * from httplogs where size >= x;
                small := select * from httplogs where size &lt; x;
                (small, large)
            }
        </query>
        <doc>A slightly more complicated example which  returns a record with two collections
            of requests.</doc>
    </step>
    </section>
    <section title="Regular expressions">

    <step><doc>
Let's have a look to regular expressions in QRAWL queries now.
        </doc>
    </step>

    <step>
        <query>
            {
                root := \x -> x parse as r"/([^/]*).*";
                root("/logos/company_logo.png")
            }
        </query>
        <doc>
This function using a regular expression to extract the root directory of a
URL. This is a feature of QRAWL: the *parse as* operator parses the string *x* as the
given regular expression and returns the string matching the group (the inner
part between parenthesis).

Therefore, if passed a URL string, *root* will return the top level directory of the file. (We will
see later what happens if the regular expression contains more than one group.)
Let's use this function in a group by query.</doc>
    </step>

    <step>
        <query>
            {
                root := \x -> x parse as r"/([^/]*).*";
                cgis := select * from httplogs where root(path) = "cgi-bin";
                select path from cgis
            }
        </query>
        <doc>We use *root* to filter requests to CGI related URLs.</doc>
    </step>

    <step>
        <query>
        {
            root := \x -> x parse as r"/([^/]*).*";
            cgis := select * from httplogs where root(path) = "cgi-bin";
            select distinct returned, *
            from cgis
            group by returned
        }
        </query>
        <doc>This is a regular group by (with nested data returned) applied
            on log lines filtered by *root*. We notice there are some
            failures because some HTTP codes are over 400.</doc>
    </step>

    <step>
        <query>
{
    root := \x -> x parse as r"/([^/]*).*";
    failure := \c -> (c >= 400);
    cgis := select * from httplogs where root(path) = "cgi-bin";
    select distinct returned, count(*), *
    from cgis
    where failure(returned)
    group by returned
}
        </query>
    <doc>We isolate failures and dig out a bit. There were several failing
         requests, all with the same error. Let's investigate a bit more.</doc>
    </step>

    <step>
        <query>
{
    root := \x -> x parse as r"/([^/]*).*";
    failure := \c -> (c >= 400);
    cgis := select * from httplogs where root(path) = "cgi-bin";
    select distinct returned, (select distinct host from *)
    from cgis
    where failure(returned)
    group by returned
}        </query>
    <doc>Here are the client host names of the failing CGI requests.</doc>
    </step>
    </section>

    <section title="Text file parsing and querying">
    <step>
    <doc>In real life, server logs are found in text files where each line encodes
an event in a custom string format. Let's see an example. Please load the file
before continuing.

* log_example ([load][1])
[1]:javascript:load_dataset("log_example")
</doc>
    </step>
    <step>
        <query>
select *
from log_example
</query>
    <doc>The HTTP requests are encoded in plain strings which have a specific format.
It is not a well structured CSV file.
We saw how QRAWL can apply regular expressions to strings. Let's use this to read the file and
tokenize the string.

First we need to access that string with a variable. For that we use the *in* syntax. Click next.</doc>
    </step>

    <step>
        <query>
select l
from l in log_example
</query>
    <doc>We will use the *parse as* keyword to apply a regular expression to each line</doc>
    </step>


    <step>
        <query>
select l parse as r"""([-\w\.\d]+)\s+-\s+-\s+\[(.*)\].*"""
from l in log_example
</query>
    <doc>See how the regular expression applied to the file now returns a record of two fields.
Let's keep adding groups in the regular expression.</doc>
    </step>

    <step>
        <query>
select l parse as r"""([-\w\.\d]+)\s+-\s+-\s+\[(.*)\]\s*"(\w+)\s+([^\s]+) (\w+)/([0-9.]+)\s*"\s+(\d+)\s+(\d+).*"""
from l in log_example
</query>
    <doc>See how the regular expression applied to the file now returns a record of fields. The records
have default numbered fields. We'd like instead to give them meaningful names. Click next to see.</doc>
    </step>

    <step>
        <query>
select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
from l in log_example
</query>
    <doc>We embedded field names in the regular expressions. They become immediately available as record
fields. Let's make a simple query.</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        from l in log_example;
    select * from log1 where size > 20000
}
</query>
    <doc>It fails because *parse as* returned a record of strings. In order to convert strings into
e.g. integers, we can turn that record of strings into a new expression (using the keyword *into*).
    </doc>
    </step>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    select * from log1 where size > 20000
}
    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    select * from log1 where size > 20000
}
</query>
    <doc>Now the records are processed into typed records (size is an integer, etc.). The query
runs successfully. Let's add a second log file.

* log_example2 ([load][1])
[1]:javascript:load_dataset("log_example2")
</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    select l
    from l in log_example2
}</query>
    <doc>It is similar to the first one except the "-" signs after the host and the date format
is different. Let's parse it with a second regular expression.</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:\d+)"""
        from l in log_example2;
    select * from log2
}</query>
    <doc>There is a failure. The regular expression did not apply to a specific line (see the error
message). This is because certain lines do not report a size with digits, but an "invalid size" with
"-". Let's fix the regular expression to accept "-" in the *size* field.</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        from l in log_example2;
    select * from log2 where size = "-"
}</query>
    <doc>Now it works. But this will be a problem for parsing sizes into integers. We should be careful
with these special cases.</doc>
    </step>
    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    // integer cleaning
    mkSize := \x -> if x = "-" then -1 else toInt(x);
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        into (date:to_epoch(date, "yyyy-MM-dd kk:mm:ss"), host, method, path,
              returned: toInt(returned), size: mkSize(size))
        from l in log_example2;
    select * from log2 where size = -1
}</query>
    <doc>We are now settled with our two logs in a unified format.</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    // integer cleaning
    mkSize := \x -> if x = "-" then -1 else toInt(x);
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        into (date:to_epoch(date, "yyyy-MM-dd kk:mm:ss"), host, method, path,
              returned: toInt(returned), size: mkSize(size))
        from l in log_example2;
    log3 := log1 bag_union log2;
    log3
}</query>
    <doc>The two logs are merged. Let's do some queries.</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    // integer cleaning
    mkSize := \x -> if x = "-" then -1 else toInt(x);
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        into (date:to_epoch(date, "yyyy-MM-dd kk:mm:ss"), host, method, path,
              returned: toInt(returned), size: mkSize(size))
        from l in log_example2;
    log3 := log1 bag_union log2;
    t1 := to_epoch("2015-07-01 06:10:00", "yyyy-MM-dd kk:mm:ss");
    t2 := to_epoch("2015-07-01 06:30:00", "yyyy-MM-dd kk:mm:ss");
    isolate := \log -> select i from i in log where i.date > t1 and i.date &lt; t2;
    isolate(log3)
}</query>
    <doc>Here we filter evengs in the log on their timestamps.</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    // integer cleaning
    mkSize := \x -> if x = "-" then -1 else toInt(x);
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        into (date:to_epoch(date, "yyyy-MM-dd kk:mm:ss"), host, method, path,
              returned: toInt(returned), size: mkSize(size))
        from l in log_example2;
    log3 := log1 bag_union log2;
    t1 := to_epoch("2015-07-01 06:10:00", "yyyy-MM-dd kk:mm:ss");
    t2 := to_epoch("2015-07-01 06:30:00", "yyyy-MM-dd kk:mm:ss");
    isolate := \log -> select i from i in log where i.date > t1 and i.date &lt; t2;
    (log1: isolate(log1), log2: isolate(log2), log3: isolate(log3))
}</query>
    <doc>Since we picked an overlapping interval, one can see *log3* is indeed a merge of *log1* and *log2*.</doc>
    </step>

    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    // integer cleaning
    mkSize := \x -> if x = "-" then -1 else toInt(x);
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        into (date:to_epoch(date, "yyyy-MM-dd kk:mm:ss"), host, method, path,
              returned: toInt(returned), size: mkSize(size))
        from l in log_example2;
    log3 := log1 bag_union log2;
    t1 := to_epoch("2015-07-01 06:10:00", "yyyy-MM-dd kk:mm:ss");
    t2 := to_epoch("2015-07-01 06:30:00", "yyyy-MM-dd kk:mm:ss");
    isolate := \log -> select i from i in log where i.date > t1 and i.date &lt; t2;
    roots := \log -> select distinct x.path parse as r"/([^/]*).*" from x in log;
    (log1: roots(isolate(log1)), log2: roots(isolate(log2)), log3: roots(isolate(log3)))
}</query>
    <doc>Maybe a simpler way to figure out by identifying roots of paths which are found in *log3*.

*Thanks for your attention*.</doc>
    </step>



    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    // integer cleaning
    mkSize := \x -> if x = "-" then -1 else toInt(x);
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        into (date:to_epoch(date, "yyyy-MM-dd kk:mm:ss"), host, method, path,
              returned: toInt(returned), size: mkSize(size))
        from l in log_example2;
    log3 := log1 bag_union log2;
    select * from log3 where returned >= 400
}</query>
    <doc>The two logs are merged.</doc>
    </step>



    <step>
        <query>
{
    log1 := select l parse as r"""(host:[-\w\.\d]+)\s+-\s+-\s+\[(date:.*)\]\s*"(method:\w+)\s+(path:[^\s]+) (protocol:\w+)/(version:[0-9.]+)\s*"\s+(returned:\d+)\s+(size:\d+).*"""
        into (date:to_epoch(date,"dd/MMM/yyyy:HH:mm:ss Z"), host, method, path,
              returned: toInt(returned), size: toInt(size))
        from l in log_example;
    // integer cleaning
    mkSize := \x -> if x = "-" then -1 else toInt(x);
    log2 := select l
        parse as r"""(host:[-\w\._]+) \[(date:\d+-\d+-\d+ \d+:\d+:\d+)\] "(method:\w+) (path:[^\s]+) (protocol:\w+)/(version:\d\.\d)" (returned:\d+) (size:[-\d]+)"""
        into (date:to_epoch(date, "yyyy-MM-dd kk:mm:ss"), host, method, path,
              returned: toInt(returned), size: mkSize(size))
        from l in log_example2;
    log3 := log1 bag_union log2;
    roots := \log -> select distinct x.path parse as r"/([^/]*).*" from x in log;
    roots(log1), roots(log2), roots(log3)
}
</query>
    <doc>Another example query.

*Thanks for your attention.*</doc>
    </step>

</section>















</guide>
